{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd4a70a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "    if IS_KAGGLE:\n",
    "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"rnn\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32df667",
   "metadata": {},
   "source": [
    "# 시계열 예측하기\n",
    "- 타임스템마다 하나의 값을 가지면 **단변량 시계열**, 여러개의 값을 가지면 **다변량 시계열**이다.\n",
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73fe39ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1)*(freq1*10 + 10))\n",
    "    series += 0.2 * np.sin((time - offsets2)*(freq1*20 + 20))\n",
    "    series = 0.2 * (np.random.rand(batch_size, n_steps)-0.5)\n",
    "    return series[..., np.newaxis].astype(np.float32)\n",
    "\n",
    "# 이 함수는 (batch_size 맥변수로) 요청한 만큼 n_stemps 길이의 여러 시계열을 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e13710a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 함수를 사용해 훈련 세트, 검증 세트, 테스트 세트를 만듬\n",
    "\n",
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86aa829",
   "metadata": {},
   "source": [
    "- RNN을 시작하기전에 기준 선능르 몇개 준비하는 것이 좋음, 그렇지 않으면 실제 기본 모델보다 성능이 나쁠 때도 잘 작동한다고 생각할 수 있음\n",
    "- 예로 각 시계열이 마지막 값을 그대로 예측하는 것입니다. 이를 **순진한 예측**이라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfd3c62",
   "metadata": {},
   "source": [
    "### 방법 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca44262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006572011"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = X_valid[:, -1]\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred)) # 평균 제곱 오차 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1446822",
   "metadata": {},
   "source": [
    "### 방법 2\n",
    "### 완전 연결 네트워크를 사용하는 것!\n",
    "- 이 네트워크는 입력마다 1차원 특성 배열을 기대하기 때문에 Flatten 층을 추가해야 함. 시계열 값의 선형 조합으로 예측하기 위해 간단한 선형 회귀 모델을 사용하겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18929a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 0s 995us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 0s 961us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 0s 892us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "63/63 [==============================] - 0s 943us/step - loss: 0.0034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0034201755188405514"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([keras.layers.Flatten(input_shape=[50, 1]),\n",
    "                                keras.layers.Dense(1)])\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "model.evaluate(X_valid, y_valid)\n",
    "\n",
    "\n",
    "# 순진한 예측보다 훨씬 나음, 0.00342"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea147f",
   "metadata": {},
   "source": [
    "### 간단한 RNN 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4020bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c05d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0033 - val_loss: 0.0034\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4da3d4",
   "metadata": {},
   "source": [
    "- 이 성능은 순진한 예측보다는 낫지만 간단한 선형 모델을 앞지르지 못함 \n",
    "- 기본 RNN의 순환 뉴런은 입력과 은닉 상태 차원(기본 RNN에서는 층의 순환 뉴럴ㄴ 개수와 같음) 마다 하나의 파라미터를 가지고 편향이 있음\n",
    "- 기본 RNN에서는 3개의 파라미터가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a656bd1",
   "metadata": {},
   "source": [
    "### 심층 RNN\n",
    "- 셀을 여러 층으로 쌓는 것이 일반적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "491c6e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 6s 21ms/step - loss: 0.0234 - val_loss: 0.0042\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 4s 21ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 4s 19ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0034 - val_loss: 0.0035\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce3877ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0034748041070997715"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2805f06e",
   "metadata": {},
   "source": [
    "- 이 RNN은 한 타임 스텝에서 다음 타임 스템으로 필요한 모든 정보를 나르기 위해 다른 순환 층의 은닉 상태를 주로 사용\n",
    "- 마지막 층의 은닉 상태는 크게 필요하지 않음\n",
    "- SimpleRNN 층은 기본적으로 tanh 활성화 함수를 사용하기 때문에 예측된 값이 -1과 1 사이 범위에 놓입니다. 다른 활성화 함수를 사용하면??\n",
    "- 이런 이유로 출력층은  Dense층으로 바꾸는 경우가 많음. **더 바르면서 정황도는 거의 비슷함**\n",
    "- 이렇게 바꾸렴녀 두번재 순환 층에서 return_sequences = True를 제거해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4371c90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 4s 15ms/step - loss: 0.0060 - val_loss: 0.0034\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0033 - val_loss: 0.0034\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 이 모델을 훈련하면 바르게 수렴하고 성능도 좋음\n",
    "# 또한 출력층으이 활성화 함수를 원하는 함수로 바꿀 수 있음\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fe241ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0034103619400411844"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25e547f",
   "metadata": {},
   "source": [
    "---\n",
    "### 여러 타임 스텝을 예측하기\n",
    "- 이전까지는 다음 스텝의 ㄱ밧만 예그했지만 타깃을 적절히 바꾸어 여러 타임 스텝 앞의 값을 손쉽게 예측할 수 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d0972a",
   "metadata": {},
   "source": [
    "#### 첫번째 방법\n",
    "- 이미 훈련된 모델을 사용하여 다음 값을 예측한 다음 이 값을 입력으로 추가하는 것!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a70800e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 4 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8000/3528159396.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep_ahead\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0my_pred_one\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_ahead\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_one\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 4 dimension(s)"
     ]
    }
   ],
   "source": [
    "np.random.seed(43)\n",
    "\n",
    "series = generate_time_series(1, n_steps + 10)\n",
    "X_new, Y_new = series[:, :n_steps], series[:, n_steps:]\n",
    "X = X_new\n",
    "\n",
    "for step_ahead in range(10):\n",
    "    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "\n",
    "Y_pred = X[:, n_steps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57733d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4148fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_forecasts(X, Y, Y_pred):\n",
    "    n_steps = X.shape[1]\n",
    "    ahead = Y.shape[1]\n",
    "    plot_series(X[0, :, 0])\n",
    "    plt.plot(np.arange(n_steps, n_steps + ahead), Y[0, :, 0], \"bo-\", label=\"Actual\")\n",
    "    plt.plot(np.arange(n_steps, n_steps + ahead), Y_pred[0, :, 0], \"rx-\", label=\"Forecast\", markersize=10)\n",
    "    plt.axis([0, n_steps + ahead, -1, 1])\n",
    "    plt.legend(fontsize=14)\n",
    "\n",
    "plot_multiple_forecasts(X_new, Y_new, Y_pred)\n",
    "save_fig(\"forecast_ahead_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63687c0f",
   "metadata": {},
   "source": [
    "### 두번째 방법\n",
    "- RNN을 훈련하여 다음 값 10개를 한 번에 예측하는 것\n",
    "- 시퀀스-투-벡터 모델을 사용하지만 1개가 아니라 값 10개를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19d6f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저 타깃을 다음 10개의 값이 담긴 벡터로 바꾸어야 한다.\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 10)\n",
    "X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
    "X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
    "X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc5e0331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 4s 15ms/step - loss: 0.0083 - val_loss: 0.0038\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0034 - val_loss: 0.0033\n"
     ]
    }
   ],
   "source": [
    "# 이제 1개의 유닛이 아니라 10개의 유닛을 가진 출력층이 필요\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, Y_train, epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7d283ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.00258692],\n",
       "        [ 0.0030446 ],\n",
       "        [-0.00097259],\n",
       "        [ 0.000591  ],\n",
       "        [-0.00680806],\n",
       "        [-0.00198271],\n",
       "        [-0.00729517],\n",
       "        [-0.00539511],\n",
       "        [ 0.00112137],\n",
       "        [ 0.00153604]]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(43)\n",
    "\n",
    "series = generate_time_series(1, 50 + 10)\n",
    "X_new, Y_new = series[:, :50, :], series[:, -10:, :]\n",
    "Y_pred = model.predict(X_new)[..., np.newaxis]\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcbdcaa",
   "metadata": {},
   "source": [
    "---\n",
    "- 마지막 스텝에서만 다음 값 10개를 예측하도록 모델을 훈련하는 대신 모든 타임 스텝에서 다음 값 10개를 예측하도록 모델 훈련\n",
    "- 시퀀스-투-벡터RNN에서 시퀀스-투 시퀀스RNN으로 바꿈\n",
    "- 훈련을 안정적으로 만들고 훈련 속도를 높임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d330c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타깃 시퀀스 준비\n",
    "np.random.seed(42)\n",
    "\n",
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 10)\n",
    "X_train = series[:7000, :n_steps]\n",
    "X_valid = series[7000:9000, :n_steps]\n",
    "X_test = series[9000:, :n_steps]\n",
    "Y = np.empty((10000, n_steps, 10))\n",
    "for step_ahead in range(1, 10 + 1):\n",
    "    Y[..., step_ahead - 1] = series[..., step_ahead:step_ahead + n_steps, 0]\n",
    "Y_train = Y[:7000]\n",
    "Y_valid = Y[7000:9000]\n",
    "Y_test = Y[9000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ed5b72",
   "metadata": {},
   "source": [
    "- 이 모델을 시퀀스-투- 시퀀스 모델로 바꾸려면 모든 순환 층(마지막 층도)에 return_sequences=True로 지정해야 함\n",
    "- 그 다음 모든 타임 스텝에서 출력을 Dense 층에 적용해야 한다. 케라스는 이런 목적으로  TimeDistributed 층을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7549791d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 4s 15ms/step - loss: 0.0044 - last_time_step_mse: 0.0049 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "# 훈련을 위해 모든 출력에 걸쳐 MSE를 계산\n",
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=0.01), metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, Y_train, epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "880fa8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43)\n",
    "\n",
    "series = generate_time_series(1, 50 + 10)\n",
    "X_new, Y_new = series[:, :50, :], series[:, 50:, :]\n",
    "Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef128691",
   "metadata": {},
   "source": [
    "### Deep RNN with Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9afe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, Y_train, epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011cfa1e",
   "metadata": {},
   "source": [
    "## 사용자 정의 메모리 셀(층 정규화)\n",
    "####  불안정한 그레디언트 문제 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6f7a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LayerNormalization\n",
    "\n",
    "\n",
    "class LNSimpleRNNCell(keras.layers.Layer): # keras.layers.Layer 클라스 상속\n",
    "    \n",
    "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units,\n",
    "                                                          activation=None)\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        if inputs is not None:\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "            dtype = inputs.dtype\n",
    "        return [tf.zeros([batch_size, self.state_size], dtype=dtype)]\n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        return norm_outputs, [norm_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c32c9295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 9s 34ms/step - loss: 0.0611 - last_time_step_mse: 0.0497 - val_loss: 0.0068 - val_last_time_step_mse: 0.0043\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0053 - last_time_step_mse: 0.0039 - val_loss: 0.0045 - val_last_time_step_mse: 0.0037\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0042 - last_time_step_mse: 0.0036 - val_loss: 0.0039 - val_last_time_step_mse: 0.0035\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 0.0038 - last_time_step_mse: 0.0035 - val_loss: 0.0037 - val_last_time_step_mse: 0.0034\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0037 - last_time_step_mse: 0.0034 - val_loss: 0.0036 - val_last_time_step_mse: 0.0034\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0036 - last_time_step_mse: 0.0034 - val_loss: 0.0035 - val_last_time_step_mse: 0.0034\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0035 - last_time_step_mse: 0.0034 - val_loss: 0.0035 - val_last_time_step_mse: 0.0034\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0035 - last_time_step_mse: 0.0034 - val_loss: 0.0035 - val_last_time_step_mse: 0.0034\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0035 - last_time_step_mse: 0.0034 - val_loss: 0.0034 - val_last_time_step_mse: 0.0034\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0034 - last_time_step_mse: 0.0034 - val_loss: 0.0034 - val_last_time_step_mse: 0.0033\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0034 - last_time_step_mse: 0.0034 - val_loss: 0.0034 - val_last_time_step_mse: 0.0033\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 0.0034 - last_time_step_mse: 0.0034 - val_loss: 0.0034 - val_last_time_step_mse: 0.0033\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0034 - last_time_step_mse: 0.0034 - val_loss: 0.0034 - val_last_time_step_mse: 0.0033\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0034 - last_time_step_mse: 0.0034 - val_loss: 0.0034 - val_last_time_step_mse: 0.0033\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0034 - last_time_step_mse: 0.0034 - val_loss: 0.0034 - val_last_time_step_mse: 0.0033\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 0.0034 - last_time_step_mse: 0.0034 - val_loss: 0.0034 - val_last_time_step_mse: 0.0033\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 0.0034 - last_time_step_mse: 0.0034 - val_loss: 0.0034 - val_last_time_step_mse: 0.0033\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0034 - last_time_step_mse: 0.0034 - val_loss: 0.0034 - val_last_time_step_mse: 0.0033\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0034 - last_time_step_mse: 0.0034 - val_loss: 0.0034 - val_last_time_step_mse: 0.0033\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0034 - last_time_step_mse: 0.0034 - val_loss: 0.0034 - val_last_time_step_mse: 0.0033\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True,\n",
    "                     input_shape=[None, 1]),\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, Y_train, epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9c9eda",
   "metadata": {},
   "source": [
    "#### 단기 기억 문제 해결하기\n",
    "- RNN을 거치면서 데이터가 변환되무로 일부 정보는 매 훈련 스텝 후 사라짐.  어느 정도 시간이 지나면 RNN 의 상태는 사실상 첫 번째 입력의 흔적을 가지고 있지 않음. 이는 심각한 문제가 될 수 있음\n",
    "- 장기 메모리를 가진 셀에서 가장 있기 있는 **LSTM셀**을 먼저 사용\n",
    "- 케라스에서는  간단하게 SimpleRNN층 대신 LSTM 층을 사용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6d04a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 8s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 6s 25ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 6s 29ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.LSTM(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, Y_train, epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f52d54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0033 - last_time_step_mse: 0.0033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0033316826447844505, 0.0033199177123606205]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b9c6e6",
   "metadata": {},
   "source": [
    "### 범용 목적이 keras.layers.RNN층에 LSTMCell을 매개변수로 지정할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcf201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.RNN(keras.layers.LSTMCell(20), return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.RNN(keras.layers.LSTMCell(20), return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b444b6",
   "metadata": {},
   "source": [
    "### 하지만 LSTM층이 GPU에서 실행할 때 최적화된 구현을 사용하므로 일반적으로 선호\n",
    "- LSTM 셀은 중요한 입력을 인식하고(입력 게이트의 역활), 장기 상태에 저장하고, 필요한 기간동안 이를 보존하고(삭제 게이트의 역활), 필요할 때마다 이를 추출하기 위해 학습\n",
    "- 그러므로 LSTM 셀은 시계열, 긴 텍스트, 오디오 녹음 등에서 장기 패턴을 잡아내는 데 놀라운 성과를 냄"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38181f5e",
   "metadata": {},
   "source": [
    "# GRU 셀\n",
    "- GRU(gated recurrent unit) 셀은 LSTM셀의 간소화된 버전이고 유사하게 작동하는 것처럼 보임(인기 많음)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b30038d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 9s 29ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 6s 27ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 6s 27ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 6s 25ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 6s 28ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 8s 39ms/step - loss: 0.0033 - last_time_step_mse: 0.0033 - val_loss: 0.0033 - val_last_time_step_mse: 0.0033\n"
     ]
    }
   ],
   "source": [
    "# 1D 합성곱 층을 사용해 시퀀스 처리하기\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, Y_train, epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6a545a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0033 - last_time_step_mse: 0.0033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.003331604413688183, 0.0033200255129486322]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "\n",
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055abc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900275c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding=\"valid\",\n",
    "                        input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, Y_train[:, 3::2], epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid[:, 3::2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b11671",
   "metadata": {},
   "source": [
    "## WaveNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f80226",
   "metadata": {},
   "source": [
    "- 첫 번째 합성곱 층이 한 번에 2개의 타임 스텝만 바라 봄, 다음 스텝은 4개, 8개의 타입 스텝을 보는 식\n",
    "- 팽창 비율을 두 배로 늘린 덕분에 네트워크는 아주 긴 시퀀스를 매우 효율적으로 처리할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=[None, 1]))\n",
    "for rate in (1, 2, 4, 8) * 2:\n",
    "    model.add(keras.layers.Conv1D(filters=20, kernel_size=2, padding=\"causal\",\n",
    "                                  activation=\"relu\", dilation_rate=rate))\n",
    "model.add(keras.layers.Conv1D(filters=10, kernel_size=1))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, Y_train, epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8237a3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e53fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13ca402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce1ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31584376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ce448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17489276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d1aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8387cd70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec576f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bb699e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f688c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d907cbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6abe257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9166bf3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ee0156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fa0e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a08e726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b0480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ed42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
