{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3629c713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    %pip install -q -U tensorflow-addons\n",
    "    %pip install -q -U transformers\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "    if IS_KAGGLE:\n",
    "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"nlp\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b6b5c6",
   "metadata": {},
   "source": [
    "# 1. Char-RNN을 사용해 셰익스피어 문체 생성하기\n",
    "- https://github.com/karpathy/char-rnn 셰익스피어 작품을 모두 다운로드 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102041e8",
   "metadata": {},
   "source": [
    "## 1.1 훈련 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2aaa7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://homl.info/shakespeare\n",
      "1122304/1115394 [==============================] - 0s 0us/step\n",
      "1130496/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 자료 다운\n",
    "\n",
    "shakespeare_url = \"https://homl.info/shakespeare\"\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "648a811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 글자를 정수로 인코딩해야 함\n",
    "# 사용자 정의 전처리 층을 만드는 것이 한 방법, 여기에서는 더 간단하게 케라스의 Tokenizer클래스를 사용\n",
    "# 이 클래스는 기본적으로 텍스트를 소문자로 바꿈, (원치 않는 경우 lower=False로 지정)\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True) \n",
    "# char_level=True로 지정하여 단어 수준 인코딩 대신 글자수준 인코딩을 만듬\n",
    "\n",
    "tokenizer.fit_on_texts(shakespeare_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f31161",
   "metadata": {},
   "source": [
    "- 이제 문자을 (또는 문장의 리스트를 ) 그랒 ID로 인코딩하거나 반대로 디코딩할 수 있음. \n",
    "- 이를 통해 텍스트에 있는 고유 글자 개수와 전체 글자 개수를 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6caa2b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 6, 9, 8, 3]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"first\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92209ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f i r s t']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99d4e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = len(tokenizer.word_index) # 고유 글자 개수\n",
    "dataset_size = tokenizer.document_count # 전체 글자 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cc89720",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe2243d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 텍스트를 인코딩하여 각 글자를 1D로 나타내 봄\n",
    "# 1 ~ 39까지 대신 0 ~ 38까지 1D를 얻기 위해 1을 빼줌\n",
    "\n",
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cc299b",
   "metadata": {},
   "source": [
    "## 1. 2 순차 데이터셋을 나누는 방법\n",
    "- 훈련세트, 검증세트, 테스트 세트가 중복되지 않도록 만드는 것이 중요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6495a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90%를 훈련 세트로 사용\n",
    "# 한 번에 한 그랒식 반환하는 tf.data.Dataset 객체를 만듬\n",
    "\n",
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c9d385",
   "metadata": {},
   "source": [
    "## 1.3 순차 데이터를 윈도 여러 개로 자르기\n",
    "- 훈련세트는 백만 개 이상의 글자로 이루어진 시퀀스 하나임. 여기에 신경망을 직접 훈련시킬 수 없음\n",
    "- 데이터셋의 window() 메서드를 사용해 이 긴 시퀀스를 작은 많은 텍스트 윈도로 변환합니다.\n",
    "- 이 데이터셋의 각 샘플은 전체 텍스트엣 매우 짧은 부분 문자열임\n",
    "- RNN은 이 부분 문자열 길이만큼만 역전파를 위해 펼쳐짐. 이를 TBPTT(Truncated BackPropagation Through Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25311b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window() 메서드를 호출하여 짧은 텍스트 윈도를 갖는 데이터셋을 만듬\n",
    "\n",
    "n_steps = 100\n",
    "window_length = n_steps + 1\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)\n",
    "\n",
    "# tip : n_steps는 튜닝 가능, 짧은 입력 시퀀스에서 RNN을 훈련하는 것은 쉽지만 당연히 이 RNN은 n_steps보다 긴 패턴을 학습할 수 없음 \n",
    "# 따라서 너무 짧게 만들어서는 안된다.\n",
    "# shift = 1로 지정하면 가장 큰 훈련세트를 만들 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eecbc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length)) # 윈도마다 batch(window_lenght)를 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8737abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows:(windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444f0b48",
   "metadata": {},
   "source": [
    "- 일반저으로 범주형 입력 특성은 원-핫 벡터나 임베딩으로 인코딩 되어야 함. 여기에서는 고유한 글자수가 적기 때문에(39개) 원-핫 벡터를\n",
    "- 글자를 인코딩합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db5caa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229dfbf1",
   "metadata": {},
   "source": [
    "--- \n",
    "- 데이터셋 준비 완료!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235e0e7c",
   "metadata": {},
   "source": [
    "## 1.4 Char-RNN 모델 만들고 훈련하기\n",
    "- 이전 글자 100개를 기반으로 다음 글자를 예측하기 우해 유닛 128개를 가진 GRU층 2개와 입력(dropout)과 은닉 상태(recurrent_dropout)에 20% 드롭아웃을 사용\n",
    "- 출력층은 TimeDistributed 클래스르 적용한 Dense 층입니다.\n",
    "- 텍스트에 있는고유한 글자 수가 39개이므로 이 층은 39개의 유닛(max_id)을 가져야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bd8434d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "31368/31368 [==============================] - 4462s 142ms/step - loss: 1.6194\n",
      "Epoch 2/2\n",
      "31368/31368 [==============================] - 4230s 135ms/step - loss: 1.5395\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                     dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                     dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628c71a9",
   "metadata": {},
   "source": [
    "## 1.5 Char-RNN 모델 사용하기\n",
    "- 위 모델에 새로운 텍스트를 주입하려면 앞에서와 같은 전처리를 해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9505046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리 함수\n",
    "\n",
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ea9ed73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 사용해 어떤 텍스트이 다음 글자를 예측\n",
    "\n",
    "X_new = preprocess([\"How are yo\"])\n",
    "Y_pred = np.argmax(model(X_new), axis=-1)\n",
    "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 첫 번째 문장, 마지막 글자\n",
    "\n",
    "\n",
    "# 정확하게 맞힌것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f233d88",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4aa4729",
   "metadata": {},
   "source": [
    "## 1.6 가짜 셰익스피어 텍스트를 생성하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d67a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model.predict(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
    "\n",
    "# 그 다음 next_char()함수를 반복 호출하여 다음 글자를 얻고 텍스트에 추가하는 작음 함수를 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54b44415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2ae6163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the more to her and servant,\n",
      "i will be good and sig\n"
     ]
    }
   ],
   "source": [
    "# 온도를 다르게 하며 테스트 해보기\n",
    "\n",
    "print(complete_text(\"t\", temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0cc8318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wtruns, my lord, and was the worship no clows\n",
      "to gu\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"w\", temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e2f799c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wore. i bise! i know he.\n",
      "fayh, nih,\n",
      "standsirousewsc\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"w\", temperature=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bff2a7",
   "metadata": {},
   "source": [
    "- 이 셰익스피어 모델은 1에 가까운 온도에서 가장 잘 작동됨. 조금 더 좋은 텍스트를 생성하려면 GRU 층과 층의 뉴런 수를 늘리고 더 오래 훈련하거나 규제(예를 들어 GRU 층을 recurrent_dropout=0.3으로 지정할 수 있음)를 추가. \n",
    "- 윈도를 크게할 수 있지만 훈련이 더 어려워짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de2ac9",
   "metadata": {},
   "source": [
    "## 1.7 상태가 있는 RNN\n",
    "- RNN이 한 훈련 배치를 처리한 후에 마지막 상태를 다음 훈련 배치의 초기상태로 사용하면 어떨까??\n",
    "- 이렇게 하면 역전파는 짧은 시퀀스에서 일어나지만 모델이 장기간 패턴을 학습할 수 있음 이를 **상태가 있는 RNN**이라고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4906f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcadbae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9097629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8092fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e9bce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa633a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e78ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e5e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf92a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabc70d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f15362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001b7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd66cf41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4452fdde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ff6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761a0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8958f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a421444a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1ef3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
