{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d367775c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "809114cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdb272e",
   "metadata": {},
   "source": [
    "# 1. 시퀀셜 API를 사용하여 이미지 분류기 만들기\n",
    "\n",
    "MNIST\n",
    "\n",
    "- 사이킷런 대신 케라스를 사용하여 MNIST나 패션 MNIST 데이터를 적재할 때 중요한 차이점은 각 이미지가 784 크기의 1D 배열이 아니라 28X28크기의 배열이라는 것!\n",
    "- 픽셀 강도 (0 ~ 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "978a2643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "40960/29515 [=========================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 3s 0us/step\n",
      "26435584/26421880 [==============================] - 3s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n",
      "4431872/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 케라스를 사용하여 데이터셋 적재하기\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc30bcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 크기 확인\n",
    "\n",
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ef95b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타입 확인\n",
    "\n",
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32bf4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 세트와 테스트 세트로 나누어져 있지만 검증 세트는 없기에 만들어 주기\n",
    "#  경사하강법으로 신경망을 훈련하기에 입력특성의 스케일을 조정 (0 ~ 255사이의 강도를 0 ~ 1사이 값으로 조정)\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc6b4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  패션 MNIST는 레이블에 해당하는 아이템을 나타내기 위해 클래스 이름의 리스트를 만들어 줌\n",
    "\n",
    "class_names = [\"T-shirt/top\", \"trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \n",
    "              \"Sneaker\", \"Bag\", \"Ankle boot\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb087fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈려 세트에 있는 첫 번째 이미지는 코트\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d988454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀셜 API를 사용하여 모델 만들기\n",
    "# 방법 1\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))   # 뉴런 300개를 가진 Dense 은닉층 추가, 활성화 함수 relu 사용    \n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))   # 뉴런 100개를 가진 Dense 은닉층 추가, 활성화 함수 relu 사용 \n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\")) # 뉴런 10개를 가진 Dense 출력층 추가, 활성화 함수 softmax 사용 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05b71918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 2\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f238f2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델의 summary() 메서드는 모델에 있는 모든 층을 출력한다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a576cf",
   "metadata": {},
   "source": [
    "첫 번째 은닉층은 784x300개의 연결 가중치와 300개의 편향을 가짐 == 235500 <br>\n",
    "모델은 훈련 데이터를 학습하기 충분한 유연성을 가진다. 또한 과대적합의 위험을 갖는다는 의미이기도 하다. <br>\n",
    "훈련 데이터가 많지 않을 경우 더욱 그렇다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec41487e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.flatten.Flatten at 0x17839f17f10>,\n",
       " <keras.layers.core.dense.Dense at 0x17839f17fa0>,\n",
       " <keras.layers.core.dense.Dense at 0x17839f15550>,\n",
       " <keras.layers.core.dense.Dense at 0x17839f19fa0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델에 있는 층의 리스트 출력하거나 인데스로 층을 쉽게 선택 가능\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f53001e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_6'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccf08a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"dense_6\") is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d9c732b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05448109,  0.05888519,  0.04701342, ...,  0.02603782,\n",
       "         0.01176836, -0.06255236],\n",
       "       [ 0.03295794, -0.06092408,  0.02065254, ..., -0.03330339,\n",
       "         0.00853574,  0.02270206],\n",
       "       [-0.01409248,  0.03250417,  0.0547045 , ..., -0.02419926,\n",
       "        -0.005446  ,  0.04853275],\n",
       "       ...,\n",
       "       [ 0.04117348, -0.04293244,  0.0107645 , ..., -0.0053723 ,\n",
       "         0.00788739,  0.03383609],\n",
       "       [-0.02908382,  0.01523595,  0.0003529 , ...,  0.05971335,\n",
       "         0.06561626,  0.00428827],\n",
       "       [-0.02205532, -0.03637466, -0.04855434, ..., -0.05842457,\n",
       "         0.06253847,  0.04241338]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 층의 모든 파라미터\n",
    "\n",
    "weights, bias = hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b42aaadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e08af50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12ddeee",
   "metadata": {},
   "source": [
    "### 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c984e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5cd12d",
   "metadata": {},
   "source": [
    "- 클래스가 배타적이므로 \"spare_categorical_crossentropy\" 손실 사용\n",
    "- 원핫벡터라면 \"categorical_crossentropy\" 손실 사용\n",
    "- 이진분류를 수행한다면 츨력층에 sigmoid 함수 사용하고 \"binary_crossentropy\" 손실 사용\n",
    "\n",
    "- 옴티마이저에 \"sgd\"를 지정하면 기본 확률저 경사 하강법(stochastic gradient descent)을 사용하여 모델을 훈련한다는 것을 의미, <br>\n",
    "  다른 말로 하면 케라스가 앞서 소개한 역전파 알고리즘을 수행\n",
    "  \n",
    "##### SGD 옵태마니저를 사용 시 학습률 튜닝이 중요!\n",
    "- keras.optimizer.SGD(lr=??), 기본값은 lr=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e869ea36",
   "metadata": {},
   "source": [
    "### 모델 훈련과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bda9d56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7380 - accuracy: 0.7589 - val_loss: 0.5111 - val_accuracy: 0.8266\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4880 - accuracy: 0.8288 - val_loss: 0.4495 - val_accuracy: 0.8492\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4426 - accuracy: 0.8450 - val_loss: 0.4353 - val_accuracy: 0.8490\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4160 - accuracy: 0.8533 - val_loss: 0.4173 - val_accuracy: 0.8532\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3970 - accuracy: 0.8607 - val_loss: 0.3974 - val_accuracy: 0.8618\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3800 - accuracy: 0.8665 - val_loss: 0.3770 - val_accuracy: 0.8684\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3671 - accuracy: 0.8703 - val_loss: 0.3799 - val_accuracy: 0.8688\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3557 - accuracy: 0.8734 - val_loss: 0.3623 - val_accuracy: 0.8752\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3445 - accuracy: 0.8773 - val_loss: 0.3555 - val_accuracy: 0.8736\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3353 - accuracy: 0.8811 - val_loss: 0.3409 - val_accuracy: 0.8804\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3270 - accuracy: 0.8837 - val_loss: 0.3361 - val_accuracy: 0.8790\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3180 - accuracy: 0.8867 - val_loss: 0.3361 - val_accuracy: 0.8834\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3112 - accuracy: 0.8885 - val_loss: 0.3373 - val_accuracy: 0.8784\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3038 - accuracy: 0.8916 - val_loss: 0.3196 - val_accuracy: 0.8842\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2976 - accuracy: 0.8929 - val_loss: 0.3361 - val_accuracy: 0.8786\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2903 - accuracy: 0.8958 - val_loss: 0.3151 - val_accuracy: 0.8862\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2848 - accuracy: 0.8975 - val_loss: 0.3206 - val_accuracy: 0.8854\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2802 - accuracy: 0.8986 - val_loss: 0.3192 - val_accuracy: 0.8858\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2741 - accuracy: 0.9010 - val_loss: 0.3148 - val_accuracy: 0.8884\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2690 - accuracy: 0.9035 - val_loss: 0.3139 - val_accuracy: 0.8864\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2643 - accuracy: 0.9049 - val_loss: 0.3079 - val_accuracy: 0.8912\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2601 - accuracy: 0.9061 - val_loss: 0.3049 - val_accuracy: 0.8912\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2544 - accuracy: 0.9071 - val_loss: 0.3060 - val_accuracy: 0.8888\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2494 - accuracy: 0.9105 - val_loss: 0.3176 - val_accuracy: 0.8842\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2460 - accuracy: 0.9115 - val_loss: 0.3037 - val_accuracy: 0.8892\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2415 - accuracy: 0.9136 - val_loss: 0.3026 - val_accuracy: 0.8892\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2377 - accuracy: 0.9153 - val_loss: 0.3025 - val_accuracy: 0.8876\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2336 - accuracy: 0.9165 - val_loss: 0.3073 - val_accuracy: 0.8876\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2302 - accuracy: 0.9167 - val_loss: 0.2996 - val_accuracy: 0.8898\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2259 - accuracy: 0.9193 - val_loss: 0.2980 - val_accuracy: 0.8886\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid)) # 검증 세트\n",
    "# 케라스는 에포크가 끝날 때마다 검증세트를 사용해 손실과 추가적인 측정 지표를 계산\n",
    "\n",
    "# 훈련세트 성능이 검증 세트보다 월등히 높다면 아미도 모델이 훈련세트에 과대적합되었을 것!\n",
    "#  걸린 시간, 훈현세트의 손실과 정확도, 검증세트의 손실과 정확도 순으로 나타남\n",
    "# 훈련정확도와 검증 정확도가 큰 차이가 없으므로 과대적합이 일어나지 않은 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb38c13",
   "metadata": {},
   "source": [
    "tip\n",
    "- validation_data 매개변수에 검증 세트를 전달하는 대신 케라스가 검증에 사용할 훈현 세트의 비율을 지정\n",
    "- 예를 들어 validation_data_split = 0.1로 쓰면 케라스는 검증에 (섞기 전의)데이터의 마지막 10%를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11161b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d688819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d69bd5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8071fe4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 곡선 시각화\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # y축 범위 0 ~ 1사이로 설정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d21f9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 991us/step - loss: 0.3315 - accuracy: 0.8830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3314962685108185, 0.8830000162124634]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6246ca3",
   "metadata": {},
   "source": [
    "### 모델을 사용해 예측을 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afc543e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.97],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "735ad9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61f54803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]\n",
    "\n",
    "# 잘 분류된것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c1bc640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43829700",
   "metadata": {},
   "source": [
    "# 2. 시퀀셜 API를 사용하여 회귀용 다층 펍셉트론 만들기\n",
    "- 캘리포니아 주택 가격 데이터셋으로 바꾸어 회귀 신경망으로 이를 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9fa89041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 적재한 후 훈련 세트, 검증 세트, 테스트 세트로 나누고 모든 특성이 스케일을 조정\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0b32b1",
   "metadata": {},
   "source": [
    "#### 분류 방식과 비슷하나 차이점은 출력층이 활성화 함수가 없는 하나의 뉴런을 가진다는 것과 손실함수로 평균 제곰 오차를 사용한다는 것!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157cd22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "429cd261",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7661 - val_loss: 1.6374\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 845us/step - loss: 1.7987 - val_loss: 0.7782\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 904us/step - loss: 1.8798 - val_loss: 0.6436\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 876us/step - loss: 0.4124 - val_loss: 0.6090\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.4043 - val_loss: 0.5222\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 861us/step - loss: 0.3852 - val_loss: 0.5179\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 846us/step - loss: 0.3725 - val_loss: 0.5109\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 900us/step - loss: 0.3858 - val_loss: 0.5122\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 841us/step - loss: 0.3892 - val_loss: 0.5279\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 859us/step - loss: 0.3661 - val_loss: 0.5024\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.3619 - val_loss: 0.4987\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.3534 - val_loss: 0.5024\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 848us/step - loss: 0.3510 - val_loss: 0.5009\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 881us/step - loss: 0.3504 - val_loss: 0.4982\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.3468 - val_loss: 0.4911\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 835us/step - loss: 0.3440 - val_loss: 0.5019\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.3420 - val_loss: 0.4930\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.3401 - val_loss: 0.4952\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.3388 - val_loss: 0.4941\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.3376 - val_loss: 0.4825\n",
      "162/162 [==============================] - 0s 578us/step - loss: 0.4253\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017839441D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋에 잡음이 많기 때문에 과대적합을 막는 용도로 뉴런 수가 적은 은닉층 하나만 사용\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss = \"mean_squared_error\", optimizer=\"sgd\")\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                   validation_data=(X_valid, y_valid))\n",
    "\n",
    "# 모델 평가\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "# 테스트\n",
    "X_new = X_test[:3]   # 새로운 샘플이라고 생각\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ddb711",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4527ba",
   "metadata": {},
   "source": [
    "# 함수형 API를 사용해 복잡한 모델 만들기\n",
    "- 입력과 출력이 여러 개거나 더 복잡한 넽트워크 토폴로지를 갖는 신경망을 만들어야 할 때\n",
    "\n",
    "## 와이드 & 딥 신경망 (Wide & Deep)\n",
    "- 이 신경마은 같은 입력의 일부 또는 전체가 출력층에 바로 연결되는 구조\n",
    "- 복잡한 패턴과 간단한 규칙을 모두 학습할 수 있는 구조\n",
    "(데이터에 있는 간단한 패턴이 연속된 변환으로 인해 왜곡될 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dfe0a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캘리포니아 주택 데이터셋\n",
    "\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc7543f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 30)           270         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 30)           930         ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1)            39          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71a4c80e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.0015 - val_loss: 0.8327\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.7612 - val_loss: 0.7165\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.6914 - val_loss: 0.6730\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.6535 - val_loss: 0.6411\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 917us/step - loss: 0.6248 - val_loss: 0.6167\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 947us/step - loss: 0.6006 - val_loss: 0.5997\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 958us/step - loss: 0.5819 - val_loss: 0.5830\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 945us/step - loss: 0.5648 - val_loss: 0.5651\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.5500 - val_loss: 0.5524\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 951us/step - loss: 0.5384 - val_loss: 0.5388\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.5259 - val_loss: 0.5312\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.5175 - val_loss: 0.5197\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.5081 - val_loss: 0.5133\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.5020 - val_loss: 0.5075\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.4943 - val_loss: 0.4985\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 917us/step - loss: 0.4871 - val_loss: 0.4928\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.4829 - val_loss: 0.4875\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 903us/step - loss: 0.4766 - val_loss: 0.4838\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4715 - val_loss: 0.4768\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 961us/step - loss: 0.4668 - val_loss: 0.4729\n",
      "162/162 [==============================] - 0s 609us/step - loss: 0.5254\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000178395DE3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfe8070",
   "metadata": {},
   "source": [
    "#### 여러개의 입력 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27bc33dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a1fc8312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.7632 - val_loss: 0.8288\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7082 - val_loss: 0.6600\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6007 - val_loss: 0.6215\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5674 - val_loss: 0.5816\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.5439 - val_loss: 0.5588\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.5267 - val_loss: 0.5460\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.5123 - val_loss: 0.5239\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.5020 - val_loss: 0.5168\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4931 - val_loss: 0.5132\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.4833 - val_loss: 0.4931\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 959us/step - loss: 0.4768 - val_loss: 0.4903\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.4692 - val_loss: 0.4803\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 938us/step - loss: 0.4657 - val_loss: 0.4783\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.4587 - val_loss: 0.4665\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 975us/step - loss: 0.4556 - val_loss: 0.4630\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 939us/step - loss: 0.4512 - val_loss: 0.4608\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.4471 - val_loss: 0.4576\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.4418 - val_loss: 0.4579\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.4383 - val_loss: 0.4478\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.4358 - val_loss: 0.4493\n",
      "162/162 [==============================] - 0s 670us/step - loss: 0.5050\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a306623",
   "metadata": {},
   "source": [
    "#### 여러개의 출력 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "472b2459",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2493c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9fb2901c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.0385 - main_output_loss: 1.7975 - aux_output_loss: 4.2074 - val_loss: 1.1518 - val_main_output_loss: 0.9056 - val_aux_output_loss: 3.3680\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9710 - main_output_loss: 0.7744 - aux_output_loss: 2.7403 - val_loss: 0.8970 - val_main_output_loss: 0.7324 - val_aux_output_loss: 2.3780\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8002 - main_output_loss: 0.6628 - aux_output_loss: 2.0372 - val_loss: 0.7932 - val_main_output_loss: 0.6732 - val_aux_output_loss: 1.8730\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7220 - main_output_loss: 0.6144 - aux_output_loss: 1.6904 - val_loss: 0.7267 - val_main_output_loss: 0.6266 - val_aux_output_loss: 1.6281\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6767 - main_output_loss: 0.5826 - aux_output_loss: 1.5234 - val_loss: 0.6884 - val_main_output_loss: 0.5979 - val_aux_output_loss: 1.5034\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6465 - main_output_loss: 0.5593 - aux_output_loss: 1.4319 - val_loss: 0.6625 - val_main_output_loss: 0.5778 - val_aux_output_loss: 1.4247\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6231 - main_output_loss: 0.5403 - aux_output_loss: 1.3681 - val_loss: 0.6354 - val_main_output_loss: 0.5530 - val_aux_output_loss: 1.3771\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6055 - main_output_loss: 0.5253 - aux_output_loss: 1.3275 - val_loss: 0.6201 - val_main_output_loss: 0.5410 - val_aux_output_loss: 1.3322\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5901 - main_output_loss: 0.5125 - aux_output_loss: 1.2888 - val_loss: 0.6071 - val_main_output_loss: 0.5302 - val_aux_output_loss: 1.2989\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5764 - main_output_loss: 0.5009 - aux_output_loss: 1.2563 - val_loss: 0.5897 - val_main_output_loss: 0.5138 - val_aux_output_loss: 1.2727\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5653 - main_output_loss: 0.4915 - aux_output_loss: 1.2300 - val_loss: 0.5816 - val_main_output_loss: 0.5077 - val_aux_output_loss: 1.2470\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5553 - main_output_loss: 0.4833 - aux_output_loss: 1.2038 - val_loss: 0.5700 - val_main_output_loss: 0.4974 - val_aux_output_loss: 1.2233\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5475 - main_output_loss: 0.4772 - aux_output_loss: 1.1810 - val_loss: 0.5627 - val_main_output_loss: 0.4917 - val_aux_output_loss: 1.2012\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5400 - main_output_loss: 0.4713 - aux_output_loss: 1.1592 - val_loss: 0.5542 - val_main_output_loss: 0.4846 - val_aux_output_loss: 1.1802\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5337 - main_output_loss: 0.4665 - aux_output_loss: 1.1381 - val_loss: 0.5479 - val_main_output_loss: 0.4797 - val_aux_output_loss: 1.1615\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5275 - main_output_loss: 0.4619 - aux_output_loss: 1.1178 - val_loss: 0.5425 - val_main_output_loss: 0.4759 - val_aux_output_loss: 1.1421\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5213 - main_output_loss: 0.4573 - aux_output_loss: 1.0971 - val_loss: 0.5353 - val_main_output_loss: 0.4704 - val_aux_output_loss: 1.1199\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5149 - main_output_loss: 0.4526 - aux_output_loss: 1.0757 - val_loss: 0.5306 - val_main_output_loss: 0.4672 - val_aux_output_loss: 1.1010\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5100 - main_output_loss: 0.4492 - aux_output_loss: 1.0572 - val_loss: 0.5237 - val_main_output_loss: 0.4614 - val_aux_output_loss: 1.0840\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5058 - main_output_loss: 0.4463 - aux_output_loss: 1.0408 - val_loss: 0.5198 - val_main_output_loss: 0.4589 - val_aux_output_loss: 1.0681\n"
     ]
    }
   ],
   "source": [
    "# 개별 손실과 총 손실을 반환\n",
    "\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d0ae6848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 777us/step - loss: 0.5658 - main_output_loss: 0.5093 - aux_output_loss: 1.0745\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffffa719",
   "metadata": {},
   "source": [
    "# 서브클래싱 API로 동적 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eaf6ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b87b6b64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.5189 - output_1_loss: 2.3586 - output_2_loss: 3.9616 - val_loss: 1.5717 - val_output_1_loss: 1.3929 - val_output_2_loss: 3.1808\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0098 - output_1_loss: 0.8569 - output_2_loss: 2.3861 - val_loss: 0.8806 - val_output_1_loss: 0.7459 - val_output_2_loss: 2.0924\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7751 - output_1_loss: 0.6656 - output_2_loss: 1.7602 - val_loss: 0.7588 - val_output_1_loss: 0.6567 - val_output_2_loss: 1.6773\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6939 - output_1_loss: 0.6073 - output_2_loss: 1.4735 - val_loss: 0.6906 - val_output_1_loss: 0.6050 - val_output_2_loss: 1.4606\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6451 - output_1_loss: 0.5696 - output_2_loss: 1.3253 - val_loss: 0.6484 - val_output_1_loss: 0.5711 - val_output_2_loss: 1.3437\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6109 - output_1_loss: 0.5407 - output_2_loss: 1.2424 - val_loss: 0.6176 - val_output_1_loss: 0.5452 - val_output_2_loss: 1.2688\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5846 - output_1_loss: 0.5178 - output_2_loss: 1.1867 - val_loss: 0.5917 - val_output_1_loss: 0.5218 - val_output_2_loss: 1.2209\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5640 - output_1_loss: 0.4991 - output_2_loss: 1.1479 - val_loss: 0.5739 - val_output_1_loss: 0.5067 - val_output_2_loss: 1.1790\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5480 - output_1_loss: 0.4851 - output_2_loss: 1.1136 - val_loss: 0.5612 - val_output_1_loss: 0.4962 - val_output_2_loss: 1.1464\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5345 - output_1_loss: 0.4735 - output_2_loss: 1.0837 - val_loss: 0.5456 - val_output_1_loss: 0.4818 - val_output_2_loss: 1.1195\n",
      "162/162 [==============================] - 0s 739us/step - loss: 0.5997 - output_1_loss: 0.5429 - output_2_loss: 1.1111\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e8d86",
   "metadata": {},
   "source": [
    "## 모델 저장과 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6cd83e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8300304d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.5143 - val_loss: 1.5909\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.8626 - val_loss: 0.7180\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.6627 - val_loss: 0.6417\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.6113 - val_loss: 0.6003\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.5797 - val_loss: 0.5729\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.5558 - val_loss: 0.5508\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.5367 - val_loss: 0.5332\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.5205 - val_loss: 0.5185\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 873us/step - loss: 0.5072 - val_loss: 0.5067\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 873us/step - loss: 0.4955 - val_loss: 0.4948\n",
      "162/162 [==============================] - 0s 609us/step - loss: 0.5523\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "659ef612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "69a3a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 모델 다시 불러오기\n",
    "\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "787a80d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.6884105],\n",
       "       [0.892621 ],\n",
       "       [1.7517455]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불러 온 모델로 예측하기\n",
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055434ee",
   "metadata": {},
   "source": [
    "## 콜백 사용하기\n",
    "- fit() 메서드의 callback 매개변수를 사용하여 케라스가 훈련의 시작이나 끝에 호출할 객체리스트를 지정할 수 있음\n",
    "- 또는 에포크의 시작이나 끝, 각 배치 처리전후에 호출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "569d5634",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53ed7a7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.6857 - val_loss: 0.9632\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.8032 - val_loss: 0.7557\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.6960 - val_loss: 0.6744\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.6350 - val_loss: 0.6155\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.5905 - val_loss: 0.5729\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5549 - val_loss: 0.5400\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.5259 - val_loss: 0.5120\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.5022 - val_loss: 0.4920\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4832 - val_loss: 0.4755\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.4670 - val_loss: 0.4594\n",
      "162/162 [==============================] - 0s 665us/step - loss: 0.5276\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True) \n",
    "# save_best_only=True :최상의 검증 세트 점수만 모델에 저장\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bc8a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "273c3a3c",
   "metadata": {},
   "source": [
    "##### EarlyStopping :  일정 에포크동안 검증세트에 대한 점수가 향상되지 않으면 훈련 멈춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109cad24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8a27f687",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4542 - val_loss: 0.4474\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 934us/step - loss: 0.4437 - val_loss: 0.4386\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.4347 - val_loss: 0.4353\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 952us/step - loss: 0.4270 - val_loss: 0.4252\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.4205 - val_loss: 0.4207\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.4151 - val_loss: 0.4165\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.4100 - val_loss: 0.4114\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.4060 - val_loss: 0.4097\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 947us/step - loss: 0.4022 - val_loss: 0.4066\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.3986 - val_loss: 0.4032\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3955 - val_loss: 0.4038\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 959us/step - loss: 0.3926 - val_loss: 0.3996\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.3903 - val_loss: 0.3980\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3875 - val_loss: 0.3957\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.3853 - val_loss: 0.3930\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3929\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.3811 - val_loss: 0.3914\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 962us/step - loss: 0.3790 - val_loss: 0.3914\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.3767 - val_loss: 0.3887\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.3751 - val_loss: 0.3875\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.3735 - val_loss: 0.3856\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.3718 - val_loss: 0.3856\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 975us/step - loss: 0.3701 - val_loss: 0.3840\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 937us/step - loss: 0.3687 - val_loss: 0.3831\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 934us/step - loss: 0.3672 - val_loss: 0.3801\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 945us/step - loss: 0.3657 - val_loss: 0.3801\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.3645 - val_loss: 0.3789\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 953us/step - loss: 0.3632 - val_loss: 0.3781\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.3622 - val_loss: 0.3771\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 940us/step - loss: 0.3610 - val_loss: 0.3761\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 934us/step - loss: 0.3598 - val_loss: 0.3747\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.3587 - val_loss: 0.3737\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.3577 - val_loss: 0.3738\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3566 - val_loss: 0.3715\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.3554 - val_loss: 0.3716\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 962us/step - loss: 0.3548 - val_loss: 0.3706\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 937us/step - loss: 0.3538 - val_loss: 0.3698\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 890us/step - loss: 0.3528 - val_loss: 0.3703\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.3521 - val_loss: 0.3684\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.3511 - val_loss: 0.3678\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.3668\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 967us/step - loss: 0.3497 - val_loss: 0.3668\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 958us/step - loss: 0.3487 - val_loss: 0.3667\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.3479 - val_loss: 0.3647\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.3473 - val_loss: 0.3651\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.3467 - val_loss: 0.3658\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3458 - val_loss: 0.3643\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.3452 - val_loss: 0.3646\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 939us/step - loss: 0.3443 - val_loss: 0.3641\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 938us/step - loss: 0.3439 - val_loss: 0.3637\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.3435 - val_loss: 0.3632\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.3428 - val_loss: 0.3624\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.3422 - val_loss: 0.3637\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 917us/step - loss: 0.3413 - val_loss: 0.3641\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.3409 - val_loss: 0.3620\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 953us/step - loss: 0.3404 - val_loss: 0.3629\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 905us/step - loss: 0.3397 - val_loss: 0.3624\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 973us/step - loss: 0.3391 - val_loss: 0.3614\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3385 - val_loss: 0.3622\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3380 - val_loss: 0.3616\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 967us/step - loss: 0.3375 - val_loss: 0.3601\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 976us/step - loss: 0.3370 - val_loss: 0.3599\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 945us/step - loss: 0.3363 - val_loss: 0.3599\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.3360 - val_loss: 0.3591\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.3351 - val_loss: 0.3598\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 934us/step - loss: 0.3349 - val_loss: 0.3579\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 892us/step - loss: 0.3341 - val_loss: 0.3585\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.3338 - val_loss: 0.3572\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.3331 - val_loss: 0.3567\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.3328 - val_loss: 0.3565\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 934us/step - loss: 0.3322 - val_loss: 0.3572\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 911us/step - loss: 0.3318 - val_loss: 0.3558\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3312 - val_loss: 0.3557\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.3309 - val_loss: 0.3556\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.3305 - val_loss: 0.3551\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.3297 - val_loss: 0.3549\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.3294 - val_loss: 0.3545\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 943us/step - loss: 0.3293 - val_loss: 0.3544\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 953us/step - loss: 0.3288 - val_loss: 0.3532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 906us/step - loss: 0.3284 - val_loss: 0.3535\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3279 - val_loss: 0.3530\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 973us/step - loss: 0.3274 - val_loss: 0.3524\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.3271 - val_loss: 0.3529\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.3265 - val_loss: 0.3532\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.3264 - val_loss: 0.3524\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.3259 - val_loss: 0.3527\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.3257 - val_loss: 0.3519\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 932us/step - loss: 0.3251 - val_loss: 0.3515\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 951us/step - loss: 0.3249 - val_loss: 0.3513\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 892us/step - loss: 0.3245 - val_loss: 0.3516\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.3242 - val_loss: 0.3502\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 917us/step - loss: 0.3238 - val_loss: 0.3492\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 892us/step - loss: 0.3234 - val_loss: 0.3498\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 928us/step - loss: 0.3231 - val_loss: 0.3491\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.3228 - val_loss: 0.3508\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 928us/step - loss: 0.3225 - val_loss: 0.3486\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.3218 - val_loss: 0.3492\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 932us/step - loss: 0.3217 - val_loss: 0.3483\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 881us/step - loss: 0.3214 - val_loss: 0.3498\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.3210 - val_loss: 0.3497\n",
      "162/162 [==============================] - 0s 615us/step - loss: 0.4027\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d7a8b2",
   "metadata": {},
   "source": [
    "# 텐서보드를 사용해 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7da7af02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2021_12_17-17_03_54'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")  # 예 :my_logs/run_201906_07-15_15_22\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c4d3492",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.0560 - val_loss: 1.0893\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8199 - val_loss: 0.7025\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6441 - val_loss: 0.6099\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5758 - val_loss: 0.5641\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.5398 - val_loss: 0.5354\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 967us/step - loss: 0.5142 - val_loss: 0.5148\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.4956 - val_loss: 0.4971\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.4798 - val_loss: 0.4837\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.4672 - val_loss: 0.4719\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.4562 - val_loss: 0.4616\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4471 - val_loss: 0.4546\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 938us/step - loss: 0.4394 - val_loss: 0.4483\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.4331 - val_loss: 0.4415\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.4370\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.4222 - val_loss: 0.4320\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4179 - val_loss: 0.4293\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4140 - val_loss: 0.4253\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.4102 - val_loss: 0.4228\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4068 - val_loss: 0.4207\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.4040 - val_loss: 0.4181\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 0.4159\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3986 - val_loss: 0.4131\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 973us/step - loss: 0.3963 - val_loss: 0.4120\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3940 - val_loss: 0.4102\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.3919 - val_loss: 0.4089\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3898 - val_loss: 0.4068\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.4058\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3862 - val_loss: 0.4044\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.4034\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.3832 - val_loss: 0.4025\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3a0c18d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-714598307fd0fade\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-714598307fd0fade\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bae3e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f022c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21360c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bedacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad119e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ebdc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cace296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c909e8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9246c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23262cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd1f98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc37bdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ad56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
