{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec6d88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    %pip install -q -U tensorflow-addons\n",
    "    %pip install -q -U transformers\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "    if IS_KAGGLE:\n",
    "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"nlp\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f590097d",
   "metadata": {},
   "source": [
    "# 1. Char-RNN을 사용해 셰익스피어 문체 생성하기\n",
    "- https://github.com/karpathy/char-rnn 셰익스피어 작품을 모두 다운로드 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b31457",
   "metadata": {},
   "source": [
    "## 1.1 훈련 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0966f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://homl.info/shakespeare\n",
      "1122304/1115394 [==============================] - 0s 0us/step\n",
      "1130496/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 자료 다운\n",
    "\n",
    "shakespeare_url = \"https://homl.info/shakespeare\"\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0928aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 글자를 정수로 인코딩해야 함\n",
    "# 사용자 정의 전처리 층을 만드는 것이 한 방법, 여기에서는 더 간단하게 케라스의 Tokenizer클래스를 사용\n",
    "# 이 클래스는 기본적으로 텍스트를 소문자로 바꿈, (원치 않는 경우 lower=False로 지정)\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True) \n",
    "# char_level=True로 지정하여 단어 수준 인코딩 대신 글자수준 인코딩을 만듬\n",
    "\n",
    "tokenizer.fit_on_texts(shakespeare_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16197f8",
   "metadata": {},
   "source": [
    "- 이제 문자을 (또는 문장의 리스트를 ) 그랒 ID로 인코딩하거나 반대로 디코딩할 수 있음. \n",
    "- 이를 통해 텍스트에 있는 고유 글자 개수와 전체 글자 개수를 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52054660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 6, 9, 8, 3]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"first\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8911463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f i r s t']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6553e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = len(tokenizer.word_index) # 고유 글자 개수\n",
    "dataset_size = tokenizer.document_count # 전체 글자 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c659b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aebd3551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 텍스트를 인코딩하여 각 글자를 1D로 나타내 봄\n",
    "# 1 ~ 39까지 대신 0 ~ 38까지 1D를 얻기 위해 1을 빼줌\n",
    "\n",
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89fccf3",
   "metadata": {},
   "source": [
    "## 1. 2 순차 데이터셋을 나누는 방법\n",
    "- 훈련세트, 검증세트, 테스트 세트가 중복되지 않도록 만드는 것이 중요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f19a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90%를 훈련 세트로 사용\n",
    "# 한 번에 한 그랒식 반환하는 tf.data.Dataset 객체를 만듬\n",
    "\n",
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685d081f",
   "metadata": {},
   "source": [
    "## 1.3 순차 데이터를 윈도 여러 개로 자르기\n",
    "- 훈련세트는 백만 개 이상의 글자로 이루어진 시퀀스 하나임. 여기에 신경망을 직접 훈련시킬 수 없음\n",
    "- 데이터셋의 window() 메서드를 사용해 이 긴 시퀀스를 작은 많은 텍스트 윈도로 변환합니다.\n",
    "- 이 데이터셋의 각 샘플은 전체 텍스트엣 매우 짧은 부분 문자열임\n",
    "- RNN은 이 부분 문자열 길이만큼만 역전파를 위해 펼쳐짐. 이를 TBPTT(Truncated BackPropagation Through Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73df09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window() 메서드를 호출하여 짧은 텍스트 윈도를 갖는 데이터셋을 만듬\n",
    "\n",
    "n_steps = 100\n",
    "window_length = n_steps + 1\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)\n",
    "\n",
    "# tip : n_steps는 튜닝 가능, 짧은 입력 시퀀스에서 RNN을 훈련하는 것은 쉽지만 당연히 이 RNN은 n_steps보다 긴 패턴을 학습할 수 없음 \n",
    "# 따라서 너무 짧게 만들어서는 안된다.\n",
    "# shift = 1로 지정하면 가장 큰 훈련세트를 만들 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e3dbc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length)) # 윈도마다 batch(window_lenght)를 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fb781e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows:(windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5996f9",
   "metadata": {},
   "source": [
    "- 일반저으로 범주형 입력 특성은 원-핫 벡터나 임베딩으로 인코딩 되어야 함. 여기에서는 고유한 글자수가 적기 때문에(39개) 원-핫 벡터를\n",
    "- 글자를 인코딩합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c5e922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b26e340",
   "metadata": {},
   "source": [
    "--- \n",
    "- 데이터셋 준비 완료!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4237d00",
   "metadata": {},
   "source": [
    "## 1.4 Char-RNN 모델 만들고 훈련하기\n",
    "- 이전 글자 100개를 기반으로 다음 글자를 예측하기 우해 유닛 128개를 가진 GRU층 2개와 입력(dropout)과 은닉 상태(recurrent_dropout)에 20% 드롭아웃을 사용\n",
    "- 출력층은 TimeDistributed 클래스르 적용한 Dense 층입니다.\n",
    "- 텍스트에 있는고유한 글자 수가 39개이므로 이 층은 39개의 유닛(max_id)을 가져야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00573ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "31368/31368 [==============================] - 4462s 142ms/step - loss: 1.6194\n",
      "Epoch 2/2\n",
      "31368/31368 [==============================] - 4230s 135ms/step - loss: 1.5395\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                     dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                     dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0a3a1d",
   "metadata": {},
   "source": [
    "## 1.5 Char-RNN 모델 사용하기\n",
    "- 위 모델에 새로운 텍스트를 주입하려면 앞에서와 같은 전처리를 해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7008ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리 함수\n",
    "\n",
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8eda7caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 사용해 어떤 텍스트이 다음 글자를 예측\n",
    "\n",
    "X_new = preprocess([\"How are yo\"])\n",
    "Y_pred = np.argmax(model(X_new), axis=-1)\n",
    "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 첫 번째 문장, 마지막 글자\n",
    "\n",
    "\n",
    "# 정확하게 맞힌것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf95223",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da019955",
   "metadata": {},
   "source": [
    "## 1.6 가짜 셰익스피어 텍스트를 생성하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de0b50fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model.predict(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
    "\n",
    "# 그 다음 next_char()함수를 반복 호출하여 다음 글자를 얻고 텍스트에 추가하는 작음 함수를 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa592fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7a1bfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the more to her and servant,\n",
      "i will be good and sig\n"
     ]
    }
   ],
   "source": [
    "# 온도를 다르게 하며 테스트 해보기\n",
    "\n",
    "print(complete_text(\"t\", temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2495032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wtruns, my lord, and was the worship no clows\n",
      "to gu\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"w\", temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e068a422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wore. i bise! i know he.\n",
      "fayh, nih,\n",
      "standsirousewsc\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"w\", temperature=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a08e7b3",
   "metadata": {},
   "source": [
    "- 이 셰익스피어 모델은 1에 가까운 온도에서 가장 잘 작동됨. 조금 더 좋은 텍스트를 생성하려면 GRU 층과 층의 뉴런 수를 늘리고 더 오래 훈련하거나 규제(예를 들어 GRU 층을 recurrent_dropout=0.3으로 지정할 수 있음)를 추가. \n",
    "- 윈도를 크게할 수 있지만 훈련이 더 어려워짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe6f97",
   "metadata": {},
   "source": [
    "## 1.7 상태가 있는 RNN\n",
    "- RNN이 한 훈련 배치를 처리한 후에 마지막 상태를 다음 훈련 배치의 초기상태로 사용하면 어떨까??\n",
    "- 이렇게 하면 역전파는 짧은 시퀀스에서 일어나지만 모델이 장기간 패턴을 학습할 수 있음 이를 **상태가 있는 RNN**이라고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2afe9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f2f502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
    "datasets = []\n",
    "for encoded_part in encoded_parts:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
    "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "    datasets.append(dataset)\n",
    "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "767b6f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상태가 있는 RNN 모델\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "                     #dropout=0.2, recurrent_dropout=0.2,\n",
    "                     dropout=0.2,\n",
    "                     batch_input_shape=[batch_size, None, max_id]),\n",
    "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "                     #dropout=0.2, recurrent_dropout=0.2),\n",
    "                     dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035eecee",
   "metadata": {},
   "source": [
    "- 에포크 끝마다 테스트를 다시 시작하기 전에 상태를 재설정해야 함. 콜백함수를 사용하여 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a9029e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetStatesCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1ba2f9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 28s 81ms/step - loss: 2.6242\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 2.2457\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 2.1168\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 37s 119ms/step - loss: 2.0396\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 37s 119ms/step - loss: 1.9880\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 1.9510\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 1.9238\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 1.8997\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 1.8798\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 1.8637\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 1.8525\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 38s 120ms/step - loss: 1.8425\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 39s 123ms/step - loss: 1.8325\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 39s 123ms/step - loss: 1.8236\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 1.8152\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 1.8080\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 1.8014\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 1.7984\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 1.7915\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 1.7869\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 1.7830\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 1.7774\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 1.7735\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 1.7694\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 1.7637\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 1.7621\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 1.7587\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 1.7561\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 1.7532\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 1.7514\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 1.7484\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 1.7462\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 1.7441\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 38s 123ms/step - loss: 1.7417\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 1.7388\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 39s 123ms/step - loss: 1.7381\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 1.7353\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 38s 123ms/step - loss: 1.7332\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 38s 123ms/step - loss: 1.7341\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 1.7298\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 38s 123ms/step - loss: 1.7283\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 39s 123ms/step - loss: 1.7257\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 1.7240\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 1.7229\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 1.7214\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 1.7194\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 1.7197\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 1.7170\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 1.7159\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 39s 123ms/step - loss: 1.7153\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, epochs=50,\n",
    "                    callbacks=[ResetStatesCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45d2cef",
   "metadata": {},
   "source": [
    "---\n",
    "- 이 모델을 훈련한 후에 훈련할 때 사용한 거솨 동일한 크기의 배치로만 예측을 만들 수 있음. 이런 제약을 없애려면 동일한 구조의 상태가 없는 모델을 만들고 상태가 있는 모델의 가중치를 복사한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f362ea54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tidy.\n",
      "\n",
      "menenius:\n",
      "mercuie, it than shall live,\n",
      "the c\n"
     ]
    }
   ],
   "source": [
    "# tip\n",
    "\n",
    "stateless_model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "\n",
    "stateless_model.build(tf.TensorShape([None, None, max_id]))\n",
    "stateless_model.set_weights(model.get_weights())\n",
    "model = stateless_model\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(complete_text(\"t\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9077c24b",
   "metadata": {},
   "source": [
    "# 2. 감성 분석\n",
    "- 영화 리뷰가 부정적인지(0), 긍정적인지(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acc15cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 1s 0us/step\n",
      "17473536/17464789 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리되어 있는 데이터셋\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data()\n",
    "X_train[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83a1316",
   "metadata": {},
   "source": [
    "- 0, 1, 2는 각각 패딩 토큰 SOS 토큰 알수 없는 단어를 의미함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b8ab53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "1654784/1641221 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<sos> this film was just brilliant casting location scenery story'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰 내용을 보고 싶다면 다음과 같이 디코딩\n",
    "\n",
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "id_to_word = {id_ + 3: word for word, id_ in word_index.items()}\n",
    "for id_, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    id_to_word[id_] = token\n",
    "\" \".join([id_to_word[id_] for id_ in X_train[0][:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd8150",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- 텐서플로 데이터셋을 사용해 원본 IMDb 리뷰를 텍스트(바이트 스트링)으로 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbd1802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\cheol\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8650e4d415794ae0883dc93dc1a17b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5609a64e37c2464ea8c6076be8ace379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-train.tfrecord...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-test.tfrecord...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-unsupervised.tfrecord...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to C:\\Users\\cheol\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
    "train_size = info.splits[\"train\"].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3ae9139",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = info.splits[\"test\"].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a4f57ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([Split('train'), Split('test'), Split('unsupervised')])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8bd7b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f30ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33051aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수를 만든다.\n",
    "\n",
    "def preprocess(X_batch, y_batch):\n",
    "    X_batch = tf.strings.substr(X_batch, 0, 300)\n",
    "    X_batch = tf.strings.regex_replace(X_batch, rb\"<br\\s*/?>\", b\" \") # 태그를 공백으로 바꿈\n",
    "    X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-Z']\", b\" \") # 대문자 소문자\n",
    "    X_batch = tf.strings.split(X_batch)\n",
    "    \n",
    "    return X_batch.to_tensor(default_value=b\"<pad>\"), y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4161b92",
   "metadata": {},
   "source": [
    "- 리뷰 텍스트를 잘라내어 각 리뷰에서 처음 300 글자만 남김. 이렇게 하면 훈련 속도를 높일 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0ce30f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting  ...\n",
      "Label: 0 = Negative\n",
      "\n",
      "Review: I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However  ...\n",
      "Label: 0 = Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in datasets[\"train\"].batch(2).take(1):\n",
    "    for review, label in zip(X_batch.numpy(), y_batch.numpy()):\n",
    "        print(\"Review:\", review.decode(\"utf-8\")[:200], \"...\")\n",
    "        print(\"Label:\", label, \"= Positive\" if label else \"= Negative\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c86371a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 53), dtype=string, numpy=\n",
       " array([[b'This', b'was', b'an', b'absolutely', b'terrible', b'movie',\n",
       "         b\"Don't\", b'be', b'lured', b'in', b'by', b'Christopher',\n",
       "         b'Walken', b'or', b'Michael', b'Ironside', b'Both', b'are',\n",
       "         b'great', b'actors', b'but', b'this', b'must', b'simply', b'be',\n",
       "         b'their', b'worst', b'role', b'in', b'history', b'Even',\n",
       "         b'their', b'great', b'acting', b'could', b'not', b'redeem',\n",
       "         b'this', b\"movie's\", b'ridiculous', b'storyline', b'This',\n",
       "         b'movie', b'is', b'an', b'early', b'nineties', b'US',\n",
       "         b'propaganda', b'pi', b'<pad>', b'<pad>', b'<pad>'],\n",
       "        [b'I', b'have', b'been', b'known', b'to', b'fall', b'asleep',\n",
       "         b'during', b'films', b'but', b'this', b'is', b'usually', b'due',\n",
       "         b'to', b'a', b'combination', b'of', b'things', b'including',\n",
       "         b'really', b'tired', b'being', b'warm', b'and', b'comfortable',\n",
       "         b'on', b'the', b'sette', b'and', b'having', b'just', b'eaten',\n",
       "         b'a', b'lot', b'However', b'on', b'this', b'occasion', b'I',\n",
       "         b'fell', b'asleep', b'because', b'the', b'film', b'was',\n",
       "         b'rubbish', b'The', b'plot', b'development', b'was', b'constant',\n",
       "         b'Cons']], dtype=object)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 0], dtype=int64)>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "188d7539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Counter로 단어의 등장 횟수를 셈\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "vocabulary = Counter()\n",
    "for X_batch, y_batch in datasets[\"train\"].batch(32).map(preprocess):\n",
    "    for review in X_batch:\n",
    "        vocabulary.update(list(review.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9329e6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'<pad>', 214309), (b'the', 61137), (b'a', 38564)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 많이 등장한 단어 확인\n",
    "\n",
    "vocabulary.most_common()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a096cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어휘 사전 중에서 가장 많이 등장한 단어 10000개만 남기고 삭제\n",
    "\n",
    "vocab_size = 10000\n",
    "truncated_vocabulary = [word for word, count in vocabulary.most_common()[:vocab_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63d0dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 단어를 1D(즉, 어휘 사전의 인덱스)로 바꾸는 전처리 단계를 추가\n",
    "\n",
    "words = tf.constant(truncated_vocabulary)\n",
    "word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n",
    "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "num_oov_buckets = 1000\n",
    "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac67d8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([   22,    12,    11, 10771], dtype=int64)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테이블에서 단어 몇 개에 대한 1D를 확인해 봄\n",
    "\n",
    "table.lookup(tf.constant(b\"This movie was faaaantastic\".split()))\n",
    "\n",
    "# faaaantastic은 없기 때문에 10000보다 크거나 같은 1D를 가진 00V 버킷 중 하나에 매핑됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b43858",
   "metadata": {},
   "source": [
    "- 리뷰를 배치로 묶고  preprocess()함수를 사용해 단어으 짧은 시퀀스로 바꿈\n",
    "- 그다음 앞서 만든 테이블을 사용하는 encode-words() 함수로 단어를 인코딩함\n",
    "- 마지막으로 다음 배치를 프리페치 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e19af18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_words(X_batch, y_batch):\n",
    "    return table.lookup(X_batch), y_batch\n",
    "\n",
    "# 훈련 세트 준비\n",
    "train_set = datasets[\"train\"].batch(32).map(preprocess)\n",
    "train_set = train_set.map(encode_words).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b55bc153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 65s 76ms/step - loss: 0.5389 - accuracy: 0.7154\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 80s 102ms/step - loss: 0.3348 - accuracy: 0.8600\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 79s 101ms/step - loss: 0.1849 - accuracy: 0.9337\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 79s 101ms/step - loss: 0.1298 - accuracy: 0.9552\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 81s 103ms/step - loss: 0.1178 - accuracy: 0.9560\n"
     ]
    }
   ],
   "source": [
    "# 모델을 만들어 훈련\n",
    "\n",
    "embed_size = 128\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size,\n",
    "                           mask_zero=True, input_shape=[None]), # 임베딩으로 변환하는 embedding 층\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.GRU(128),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a2abf7",
   "metadata": {},
   "source": [
    "## 2.1 마스킹\n",
    "- 패딩 토큰을 무시하도록 모데에게 알려주어 실제 의미가 있는 데이터에 집중할 수 있게 만드는 것\n",
    "- Embedding 층을 만들 때 mask_zero= True 매개변수 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689231c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "embed_size = 128\n",
    "inputs = keras.layers.Input(shape=[None])\n",
    "mask = keras.layers.Lambda(lambda inputs: K.not_equal(inputs, 0))(inputs)\n",
    "z = keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size)(inputs)\n",
    "z = keras.layers.GRU(128, return_sequences=True)(z, mask=mask)\n",
    "z = keras.layers.GRU(128)(z, mask=mask)\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
    "model = keras.models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f50ee",
   "metadata": {},
   "source": [
    "## 사전훈련된 임베딩 재사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e40c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "TFHUB_CACHE_DIR = os.path.join(os.curdir, \"my_tfhub_cache\")\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = TFHUB_CACHE_DIR\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "model = keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\",\n",
    "                   dtype=tf.string, input_shape=[], output_shape=[50]), # 모듈 다운로드, 이 모듈의 이름은 \"문장 인코더\"\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(TFHUB_CACHE_DIR):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirpath, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
    "train_size = info.splits[\"train\"].num_examples\n",
    "batch_size = 32\n",
    "train_set = datasets[\"train\"].batch(batch_size).prefetch(1)\n",
    "history = model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085677be",
   "metadata": {},
   "source": [
    "# 3. 신경망 기계 번역을 위한 인코더-디코더 네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "83199329",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100\n",
    "embed_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1048d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
    "\n",
    "embeddings = keras.layers.Embedding(vocab_size, embed_size)\n",
    "encoder_embeddings = embeddings(encoder_inputs)\n",
    "decoder_embeddings = embeddings(decoder_inputs)\n",
    "\n",
    "encoder = keras.layers.LSTM(512, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "decoder_cell = keras.layers.LSTMCell(512)\n",
    "output_layer = keras.layers.Dense(vocab_size)\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler,\n",
    "                                                 output_layer=output_layer)\n",
    "final_outputs, final_state, final_sequence_lengths = decoder(\n",
    "    decoder_embeddings, initial_state=encoder_state,\n",
    "    sequence_length=sequence_lengths)\n",
    "Y_proba = tf.nn.softmax(final_outputs.rnn_output)\n",
    "\n",
    "model = keras.models.Model(\n",
    "    inputs=[encoder_inputs, decoder_inputs, sequence_lengths],\n",
    "    outputs=[Y_proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "35c03fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ed79bbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "32/32 [==============================] - 6s 111ms/step - loss: 4.6052\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 3s 106ms/step - loss: 4.6031\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randint(100, size=10*1000).reshape(1000, 10)\n",
    "Y = np.random.randint(100, size=15*1000).reshape(1000, 15)\n",
    "X_decoder = np.c_[np.zeros((1000, 1)), Y[:, :-1]]\n",
    "seq_lengths = np.full([1000], 15)\n",
    "\n",
    "history = model.fit([X, X_decoder, seq_lengths], Y, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623e4445",
   "metadata": {},
   "source": [
    "## 3.1 양방향 RNN\n",
    "- keras에서 양방향 순환 층ㅇ르 구현하려면 keras.layers.Bidirectional으로 순환 층을 감쌉니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e594459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_14 (GRU)                (None, None, 10)          660       \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 20)         1320      \n",
      " l)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,980\n",
      "Trainable params: 1,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(10, return_sequences=True, input_shape=[None, 10]),\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(10, return_sequences=True)) \n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4239e1e9",
   "metadata": {},
   "source": [
    "# 4. 어텐션 메커니즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0253a5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d9704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a63e6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4f9757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9927db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260fe64c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd4674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b206bd45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7355c126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c349e525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d158ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a247b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4ac961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b39c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8916d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f0e6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599b472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e60cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
